# Hockey Game Simulator
# Ai Ethics Questions: Assignments 1 and 2
Assignment #1

Question 1
The 5 fundamental rights for the basis for Trustworthy AI are respect for human dignity, freedom of the individual, respect for democracy, justice and the rule of law, equality, non-discrimination and solidarity and citizens’ rights. 

Human dignity: 
Microsoft has introduced Seeing AI which is a free AI-powered app designed to empower visually impaired individuals in their daily lives. Users have shared how the app has transformed their independence thus enabling them to read product labels and navigate store aisles without assistance. Leveraging a smartphone’s camera, Seeing AI provides powerful functionalities which include facial recognition in social settings and environmental descriptions. By helping users engage with the world more confidently, the app enhances their human dignity while reinforcing a sense of autonomy and self-worth.

Freedom of the individual: 
In 2019, the French data protection authority, CNIL, fined Google €50 million for GDPR violations. The company failed to provide clear and accessible information about how user data was processed and lacked valid consent for personalized advertising. This action demonstrated a commitment to ensuring that individuals retain control over their data thus promoting their individual freedom to make informed decisions about its use.

Respect for democracy, justice and the rule of law:
One example for respect of democracy and rule of law is Brazil's use of AI-powered tools during the 2022 presidential election to combat misinformation. The Supreme Electoral Court deployed systems to identify and flag false content on social media to ensure voters received accurate information. This initiative upheld democratic processes by safeguarding election integrity thus respecting the country’s cultural diversity and operating under constitutional frameworks. By incorporating human review to confirm AI findings, the system ensured due process and minimized errors, demonstrating how AI can enhance transparency, fairness, and trust in democratic institutions while adhering to the rule of law.

Promoting equality, non-discrimination, and solidarity:
Microsoft’s Adaptive Controller for gaming is designed specifically for individuals with disabilities. This customizable device ensures inclusivity by addressing the needs of those who may struggle with traditional controllers thus providing equal access to gaming experiences. By prioritizing accessibility and compatibility with various assistive devices the Adaptive Controller fosters solidarity and respects the dignity of individuals with disabilities, allowing them to fully participate in gaming. Its impact extends beyond gaming by setting a standard for inclusive design in technology and encouraging greater accessibility across industries.

Safeguarding citizens’ rights:
One example of safeguarding citizens’ rights is Estonia’s e-Residency program and e-Governance systems which uses AI and digital tools to provide seamless access to public services. Through secure digital identities citizens can vote, file taxes, and access public records entirely online thus ensuring the right to good administration and transparency. Additionally, the e-Residency program extends access to services beyond its borders and allows individuals worldwide to establish businesses and interact with Estonian systems. By streamlining processes, enhancing transparency and fostering democratic participation through digital platforms, Estonia demonstrates how AI can uphold citizens’ rights while promoting efficient and inclusive governance.

Sources:
https://www.afb.org/aw/18/8/15185
https://www.globalprivacyblog.com/2019/01/french-data-protection-authority-issues-e50-million-fine-in-landmark-gdpr-case/
https://www.unesco.org/ethics-ai/en/brazil
https://www.xbox.com/en-US/accessories/controllers/xbox-adaptive-controller
https://e-estonia.com/solutions/estonian-e-identity/e-residency/

Question 2
The principle of respect for human autonomy: 
One example is IBM’s Watson for Oncology tool used in cancer treatment. This AI system analyzes large volumes of medical literature, patient records and clinical trial data to provide doctors with evidence-based treatment options tailored to individual patients.
For instance, when a patient is diagnosed with breast cancer, Watson for Oncology might recommend various treatment plans based on the specific type and stage of cancer. It also considers factors like the patient’s medical history and genetic profile in its diagnostic. However, the oncologist retains full control over the decision-making process using the AI's insights to inform their expertise rather than being dictated by the system.
This setup respects both the doctor’s professional autonomy and the patient’s autonomy by empowering them to make collaborative decisions about treatment options thus ensuring that the AI serves as a supportive tool rather than a replacement for human judgment thus keeping the autonomy of the humans involved.

The principle of prevention of harm: 
An example of the principle of prevention of harm is shown with Waymo's self-driving cars, developed by Google's parent company, Alphabet. Waymo vehicles are equipped with advanced sensors such as LiDAR, cameras and radar which work together to detect and respond to their surroundings in real time. Thus, for example, a Waymo car driving in a residential neighborhood can recognize a child running after a ball into the street. The AI system immediately identifies the potential hazard, calculates the safest course of action and applies the brakes to avoid an accident. This process ensures the protection of both the child’s and passengers’ physical integrity. Studies have also shown that in many cases these Waymo systems have an even faster response time than a regular person thus increasing the safety of human life.
Additionally, Waymo employs rigorous testing which includes billions of simulated miles and millions of real-world miles driven under controlled conditions, to ensure the system's robustness and resistance to errors or malicious attacks. These vehicles also prioritize inclusivity by recognizing and responding to individuals with disabilities such as wheelchair users which ensure they are treated with care and respect. This proactive focus on safety and inclusivity aligns with the principle of preventing harm to human life and societal bias making the world a better place to live.

The principle of fairness: 
An example of these fairness principles can be seen in AI systems used for loan approvals. To ensure fairness, these systems must equitably distribute benefits and costs by offering equal opportunities to all applicants, regardless of their background, and eliminating biases that could lead to discrimination. Decisions should be based solely on relevant financial data, avoiding factors like race or gender. The system must also respect applicants' freedom of choice by being transparent about decision-making criteria, ensuring individuals are not deceived or stigmatized. 
Additionally, procedural fairness requires that applicants can contest decisions they believe are unfair. This involves providing clear explanations of how decisions were made and ensuring the entity accountable for the decision is identifiable and accessible for appeals. By adhering to these principles, AI systems in loan approvals can promote fairness, transparency, and accountability.

The principle of explicability: 
A notable real-life example highlighting the importance of explicability in AI systems is the Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) algorithm, used in the U.S. judicial system to assess the likelihood of a defendant reoffending. In 2016, an investigation by ProPublica revealed that COMPAS exhibited racial bias, disproportionately assigning higher risk scores to Black defendants compared to white defendants. This bias persisted despite the algorithm not explicitly considering race as a factor. The opacity of COMPAS's decision-making process, which is often referred to as a "black box," meant that defendants and legal professionals could not understand or challenge the rationale behind the risk scores assigned. This lack of transparency undermined trust in the system and raised significant ethical and legal concerns about fairness and accountability in algorithmic decision-making. That is why it is so important to introduce explicability when creating AI systems.

Sources:
https://pmc.ncbi.nlm.nih.gov/articles/PMC6656482/
https://abcnews.go.com/Technology/waymo-takes-streets-cities/story?id=113248606
https://fairplay.ai/upgrade-tech-ensure-ai-based-lending-fair/
https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm

Assignment #4

Question 1
Now that it is 2025 there are many medical devices on the market that are readily available to consumers but are not all approved by the FDA. One such device that is actually approved by the FDA is a heart monitoring device called HeartGuide. It is the first FDA cleared fitness watch that is a true and serous blood pressure monitor. You just have to press a button and lift it up to heart level. Then at this point it buzzes when it reaches the correct elevation and then takes the measurement which takes somewhere around 30 seconds in which you need to stay still. Even though you have to go through this process the benefits of this current device are numerous with one of the best examples being its portability. In the many articles about this device, it is mentioned that users love the advantage of checking their blood pressure anywhere they go. Instead of carrying a big device around, such as an electronic oscillometic blood pressure measuring device which is bulky, this device is just attached to your arm all day. Many of the users in the articles also mention that they check more often just because of the convenience of the device thus they are presumably checking their blood pressure more often than they would have otherwise. It also keeps track of each reading and puts the data information into a graph on the device’s app on that person’s smartphone where you can see how at different times of the day your blood pressure fluctuates. 

Sources:
https://www.cnet.com/tech/mobile/omron-heartguide-my-life-with-a-blood-pressure-smartwatch/

Question 2
However, there are also disadvantages for the HeartGuide fitness watch as well as ethical concerns. Users in the multiple articles I read have stated that this watch is very bulky and likened it to older GPS watches they wore in the past. Other users said it was also hard to sleep with as again the bulkiness of the watch is not desirable when sleeping. One of the ethical concerns with these fitness watches, including this watch, are the concerns with the company sharing that data collected by the watch and app from the consumer. This concern is highlighted by the National Library of Medicine or the NIH which is a United States government funded regulatory body that deals with these medical concerns. It is stated by the maker and seller of the HeartGuide, OMRON, in their privacy policy that they do give your information to third parties with the option to opt out. So, you have to actually know their policy beforehand in order to opt out from having your data given away. I listed a link to their privacy policy below under the sources header. I could also not find a statement from OMRON if they are selling this information to third parties or not which could be a real ethical issue thus something to keep in mind if people want to consider the pros and cons of buying the product.

Sources:
https://pmc.ncbi.nlm.nih.gov/articles/PMC7843431/
https://www.omron.com/global/en/general/privacy/


The **Hockey Game Simulator** is a Python-based simulation that creates a dynamic hockey league with teams, players, and game events. It simulates real-game scenarios including regular periods, overtime, shootouts, injuries, line changes, and energy management.

## Features

- **Team Creation:**
  - Generates 32 unique teams in a "City - Team Name" format.
  - Each team includes 20 players (18 Skaters and 2 Goaltenders).
  - Skaters have random jersey numbers (1-99), offensive values (50-100), defensive values (50-100), and energy (1-25).
  - Goaltenders have random jersey numbers (1-99), defensive values (60-90), and energy (1-25).
  - Four lines per team with 5 skaters each (a skater can appear in multiple lines but only once per line).

- **Game Simulation:**
  - Simulates 3 regular periods (each with 10 iterations).
  - If needed, simulates a 10-iteration overtime period.
  - Conducts a shootout if the score remains tied after overtime, with a minimum of 3 rounds and sudden-death rounds as required.
  - Includes mechanics for:
    - **Line management:** Switches lines if the current line’s average energy falls below 18.
    - **Injury simulation:** Based on a probability formula; injured players are replaced immediately.
    - **Goal scoring:** Uses calculated shot and goal probabilities.
    - **Energy management:** Active skaters lose energy while inactive ones gain energy.

- **Interactive Menu:**
  - Simulate one or more games.
  - Display detailed statistics for each team including total games played, wins, losses (by game type), goals for/against, and injury count.
  - Adjust simulation parameters (e.g., toggle prints for goals, injuries, line changes).
  - Reset game data.

## Installation

1. **Clone the Repository:**
   ```bash
   git clone https://github.com/yourusername/hockey-game-simulator.git
   cd hockey-game-simulator

2. **Create a Virtual Environment (Optional but recommended):**

3. **Install Requirements:**
If there are any external dependencies listed in `requirements.txt`:
*Note: This project uses only Python's built-in libraries, so no additional packages may be required.*

## Usage

To run the simulator, execute the main script:

You will be greeted with an interactive menu. Follow the prompts to:
- Simulate games.
- View detailed team statistics.
- Adjust simulation parameters.
- Reset data.
- Exit the simulator.

## Project Structure
hockey-game-simulator/ ├── README.md ├── .gitignore ├── hockey_game_simulator.py ├── requirements.txt # (if applicable) └── docs/ # (optional, for additional documentation)

## Contributing

Contributions are welcome! If you'd like to improve the project or add new features:
1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Submit a pull request detailing your changes.

## Acknowledgements

- Thanks to the instructors and mentors for their guidance.
- Special thanks to all contributors who helped improve this project.
